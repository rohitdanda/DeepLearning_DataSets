{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR100 _Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/O5ny/T04H4aKb0EVm4qs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitdanda/DeepLearning_DataSets/blob/master/CIFAR100__Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW4i4dBz2Fl7",
        "colab_type": "text"
      },
      "source": [
        "importing the CIFAR100 datasets from keras "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M0PGjwH2Aw7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "890c4234-e33a-4203-bb21-1bc877f1a01f"
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=cifar100.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XvSGUFp2o0h",
        "colab_type": "text"
      },
      "source": [
        "Our train datasets is okay we need fix the one hot encoding for labels now "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKMcRpfb2f8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "y_train_Cat = to_categorical(y_train,100)\n",
        "y_test_Cat = to_categorical(y_test,100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNXaJkKG3Hn-",
        "colab_type": "text"
      },
      "source": [
        "No we need to normalize the pixel values in the train datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfGqjTdD3EtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train/x_train.max()\n",
        "x_test = x_test/x_train.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvbzbbku3ttu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c894d981-047d-429a-e15d-d3a6679aeb83"
      },
      "source": [
        "x_train.max()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6okUdk7u4iv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3595caed-d51b-4cd1-844f-e0e30128d12a"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sv0DGJ14l5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOYBVKs44H7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "outputId": "ccb84667-38a0-49bc-cba4-d5a928937782"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=128,kernel_size=(4,4),input_shape=(32,32,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters=64,kernel_size=(4,4),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(100,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 29, 29, 128)       6272      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 11, 11, 64)        131136    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               51300     \n",
            "=================================================================\n",
            "Total params: 1,533,732\n",
            "Trainable params: 1,533,732\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHPcuIgwXsq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTcsSr2p5N2K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5edcf31-5927-43cd-fc7f-dad058bfb01c"
      },
      "source": [
        "model.fit(x_train,y_train_Cat,epochs=100)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50000/50000 [==============================] - 13s 255us/step - loss: 2.6214 - acc: 0.3264\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 13s 254us/step - loss: 2.5988 - acc: 0.3316\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 13s 257us/step - loss: 2.5888 - acc: 0.3324\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 2.5682 - acc: 0.3363\n",
            "Epoch 5/100\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.5565 - acc: 0.3433\n",
            "Epoch 6/100\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.5415 - acc: 0.3433\n",
            "Epoch 7/100\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 2.5264 - acc: 0.3451\n",
            "Epoch 8/100\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 2.5132 - acc: 0.3504\n",
            "Epoch 9/100\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 2.5077 - acc: 0.3505\n",
            "Epoch 10/100\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 2.4891 - acc: 0.3521\n",
            "Epoch 11/100\n",
            "50000/50000 [==============================] - 13s 252us/step - loss: 2.4666 - acc: 0.3590\n",
            "Epoch 12/100\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 2.4647 - acc: 0.3602\n",
            "Epoch 13/100\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.4441 - acc: 0.3636\n",
            "Epoch 14/100\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 2.4443 - acc: 0.3622\n",
            "Epoch 15/100\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 2.4360 - acc: 0.3669\n",
            "Epoch 16/100\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.4229 - acc: 0.3696\n",
            "Epoch 17/100\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 2.4221 - acc: 0.3701\n",
            "Epoch 18/100\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 2.4135 - acc: 0.3689\n",
            "Epoch 19/100\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 2.3986 - acc: 0.3745\n",
            "Epoch 20/100\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 2.3904 - acc: 0.3763\n",
            "Epoch 21/100\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.3961 - acc: 0.3775\n",
            "Epoch 22/100\n",
            "50000/50000 [==============================] - 13s 262us/step - loss: 2.3785 - acc: 0.3801\n",
            "Epoch 23/100\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 2.3558 - acc: 0.3837\n",
            "Epoch 24/100\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 2.3603 - acc: 0.3844\n",
            "Epoch 25/100\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 2.3458 - acc: 0.3894\n",
            "Epoch 26/100\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 2.3501 - acc: 0.3851\n",
            "Epoch 27/100\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 2.3361 - acc: 0.3888\n",
            "Epoch 28/100\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 2.3343 - acc: 0.3885\n",
            "Epoch 29/100\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 2.3330 - acc: 0.3891\n",
            "Epoch 30/100\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 2.3230 - acc: 0.3931\n",
            "Epoch 31/100\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 2.3200 - acc: 0.3913\n",
            "Epoch 32/100\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 2.3230 - acc: 0.3929\n",
            "Epoch 33/100\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 2.2995 - acc: 0.3965\n",
            "Epoch 34/100\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 2.2958 - acc: 0.3987\n",
            "Epoch 35/100\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 2.2869 - acc: 0.4002\n",
            "Epoch 36/100\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 2.2894 - acc: 0.3970\n",
            "Epoch 37/100\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 2.2823 - acc: 0.4006\n",
            "Epoch 38/100\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 2.2766 - acc: 0.4037\n",
            "Epoch 39/100\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 2.2688 - acc: 0.4038\n",
            "Epoch 40/100\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 2.2675 - acc: 0.4058\n",
            "Epoch 41/100\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 2.2690 - acc: 0.4045\n",
            "Epoch 42/100\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 2.2789 - acc: 0.4034\n",
            "Epoch 43/100\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 2.2637 - acc: 0.4055\n",
            "Epoch 44/100\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 2.2434 - acc: 0.4114\n",
            "Epoch 45/100\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 2.2554 - acc: 0.4062\n",
            "Epoch 46/100\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 2.2401 - acc: 0.4118\n",
            "Epoch 47/100\n",
            "50000/50000 [==============================] - 13s 250us/step - loss: 2.2359 - acc: 0.4120\n",
            "Epoch 48/100\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 2.2529 - acc: 0.4071\n",
            "Epoch 49/100\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 2.2219 - acc: 0.4178\n",
            "Epoch 50/100\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 2.2208 - acc: 0.4165\n",
            "Epoch 51/100\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 2.2145 - acc: 0.4196\n",
            "Epoch 52/100\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 2.2252 - acc: 0.4153\n",
            "Epoch 53/100\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 2.2213 - acc: 0.4164\n",
            "Epoch 54/100\n",
            "50000/50000 [==============================] - 12s 246us/step - loss: 2.2131 - acc: 0.4189\n",
            "Epoch 55/100\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 2.2102 - acc: 0.4192\n",
            "Epoch 56/100\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 2.2131 - acc: 0.4230\n",
            "Epoch 57/100\n",
            "50000/50000 [==============================] - 12s 236us/step - loss: 2.1933 - acc: 0.4282\n",
            "Epoch 58/100\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 2.2042 - acc: 0.4240\n",
            "Epoch 59/100\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 2.2129 - acc: 0.4206\n",
            "Epoch 60/100\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 2.1906 - acc: 0.4243\n",
            "Epoch 61/100\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 2.1930 - acc: 0.4251\n",
            "Epoch 62/100\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 2.1849 - acc: 0.4263\n",
            "Epoch 63/100\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 2.1951 - acc: 0.4264\n",
            "Epoch 64/100\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 2.1928 - acc: 0.4257\n",
            "Epoch 65/100\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 2.1864 - acc: 0.4289\n",
            "Epoch 66/100\n",
            "50000/50000 [==============================] - 12s 249us/step - loss: 2.1866 - acc: 0.4276\n",
            "Epoch 67/100\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 2.1821 - acc: 0.4321\n",
            "Epoch 68/100\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 2.1661 - acc: 0.4327\n",
            "Epoch 69/100\n",
            "50000/50000 [==============================] - 12s 238us/step - loss: 2.1742 - acc: 0.4313\n",
            "Epoch 70/100\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 2.1704 - acc: 0.4320\n",
            "Epoch 71/100\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 2.1617 - acc: 0.4349\n",
            "Epoch 72/100\n",
            "50000/50000 [==============================] - 12s 239us/step - loss: 2.1776 - acc: 0.4307\n",
            "Epoch 73/100\n",
            "50000/50000 [==============================] - 12s 248us/step - loss: 2.1795 - acc: 0.4317\n",
            "Epoch 74/100\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 2.1652 - acc: 0.4336\n",
            "Epoch 75/100\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 2.1612 - acc: 0.4341\n",
            "Epoch 76/100\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 2.1608 - acc: 0.4357\n",
            "Epoch 77/100\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 2.1550 - acc: 0.4347\n",
            "Epoch 78/100\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 2.1654 - acc: 0.4366\n",
            "Epoch 79/100\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 2.1473 - acc: 0.4365\n",
            "Epoch 80/100\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 2.1503 - acc: 0.4370\n",
            "Epoch 81/100\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 2.1467 - acc: 0.4378\n",
            "Epoch 82/100\n",
            "50000/50000 [==============================] - 12s 240us/step - loss: 2.1316 - acc: 0.4405\n",
            "Epoch 83/100\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 2.1379 - acc: 0.4376\n",
            "Epoch 84/100\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 2.1270 - acc: 0.4438\n",
            "Epoch 85/100\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 2.1188 - acc: 0.4464\n",
            "Epoch 86/100\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 2.1231 - acc: 0.4442\n",
            "Epoch 87/100\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 2.1329 - acc: 0.4390\n",
            "Epoch 88/100\n",
            "50000/50000 [==============================] - 12s 243us/step - loss: 2.1335 - acc: 0.4446\n",
            "Epoch 89/100\n",
            "50000/50000 [==============================] - 12s 244us/step - loss: 2.1168 - acc: 0.4461\n",
            "Epoch 90/100\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 2.1347 - acc: 0.4423\n",
            "Epoch 91/100\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 2.1245 - acc: 0.4431\n",
            "Epoch 92/100\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 2.1359 - acc: 0.4420\n",
            "Epoch 93/100\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 2.1265 - acc: 0.4424\n",
            "Epoch 94/100\n",
            "50000/50000 [==============================] - 12s 247us/step - loss: 2.1412 - acc: 0.4410\n",
            "Epoch 95/100\n",
            "50000/50000 [==============================] - 12s 242us/step - loss: 2.1301 - acc: 0.4448\n",
            "Epoch 96/100\n",
            "50000/50000 [==============================] - 12s 250us/step - loss: 2.1327 - acc: 0.4426\n",
            "Epoch 97/100\n",
            "50000/50000 [==============================] - 12s 241us/step - loss: 2.1075 - acc: 0.4523\n",
            "Epoch 98/100\n",
            "50000/50000 [==============================] - 13s 251us/step - loss: 2.1088 - acc: 0.4473\n",
            "Epoch 99/100\n",
            "50000/50000 [==============================] - 13s 253us/step - loss: 2.1205 - acc: 0.4462\n",
            "Epoch 100/100\n",
            "50000/50000 [==============================] - 12s 245us/step - loss: 2.1150 - acc: 0.4495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee9ea22780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHLUSXR75Veh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8ee79f2a-9972-4eb1-c266-b06e5ff2d750"
      },
      "source": [
        "model.evaluate(x_test,y_test_Cat,verbose=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 103us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14.172730444335938, 0.1158]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DQCXNGXBKRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}